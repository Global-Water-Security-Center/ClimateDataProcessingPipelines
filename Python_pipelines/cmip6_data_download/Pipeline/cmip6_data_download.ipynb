{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The **cmip6_climate_data function** serves as a highly valuable tool in the realm of climate data analysis and research. Its primary utility lies in its ability to streamline the process of accessing and downloading specific subsets of climate data from the CMIP6 (Coupled Model Intercomparison Project Phase 6) dataset. Here are some key points highlighting its utility:\n",
        "\n",
        "1) **Customized Data Retrieval:** Users can specify various parameters like the climate model, timeframe, ensemble member, and climate variable. This customization allows researchers to target their data acquisition precisely, which is crucial for specific climate studies.\n",
        "\n",
        "2) **Efficient Year Range Selection:** By enabling users to select a specific range of years, the pipeline provides a focused approach to data acquisition, avoiding the need to manually sort through irrelevant data, saving time and computational resources.\n",
        "\n",
        "3) **Automated Batch Downloading:** The function automates the tedious process of downloading multiple files, which is particularly beneficial when dealing with large datasets typical in climate research.\n",
        "\n",
        "4) **Organized Data Storage:** By allowing users to specify an output folder, the pipeline ensures that the downloaded data is well-organized and easily accessible for subsequent analysis.\n",
        "\n",
        "5) **Ease of Use and Reproducibility:** The function is designed with clarity and ease of use in mind, making it accessible even to those with basic programming knowledge. This ease of use promotes reproducibility in research, as other researchers can replicate the data acquisition process with minimal effort.\n",
        "\n",
        "6) **Time-Saving and Resource-Efficient:** By automating data download and organization, the pipeline significantly reduces the time and effort required for data preparation, enabling researchers to focus more on analysis and interpretation.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a-1ujcfWSjFm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing the modules**"
      ],
      "metadata": {
        "id": "Shgg3hxNTn7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests  ### allows us to interact the interface which has the data (sending requests to the portal)\n",
        "import xml.etree.ElementTree as ET  # For parsing XML\n",
        "import time  # For adding delays between requests\n",
        "import os  # For handling file paths and directories"
      ],
      "metadata": {
        "id": "NApXgTKMSq2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the function**\n",
        "\n",
        "**Parameters:**\n",
        "\n",
        "**model**: Climate model name as a string (e.g., 'ACCESS-CM2')\n",
        "\n",
        "**timeframe**: Time frame of the data (e.g., 'historical', 'SSP126', 'SSP245').\n",
        "\n",
        "**ensemble:** Ensemble member (e.g., 'r1i1p1f1').\n",
        "\n",
        "**climate_variable (str)**: Climate variable as a string(e.g., 'pr' for precipitation).\n",
        "\n",
        "**start_year (int)**: **bold text** Start year of the data range.\n",
        "\n",
        "**end_year (int)**: End year of the data range.\n",
        "\n",
        "**output_folder (str)**: Path to the output folder where files will be saved.\n"
      ],
      "metadata": {
        "id": "_1P27uNHT04w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def cmip6_climate_data(model, timeframe, ensemble, climate_variable, start_year, end_year, output_folder):\n",
        "    \"\"\"\n",
        "    Download climate data files from the CMIP6 dataset.\n",
        "\n",
        "    This function downloads data for a specified climate model, timeframe,\n",
        "    ensemble member, and climate variable for a range of years. The files\n",
        "    are saved in a specified output folder.\n",
        "\n",
        "    Parameters:\n",
        "    model (str): Climate model name (e.g., 'ACCESS-CM2').\n",
        "    timeframe (str): Time frame of the data (e.g., 'historical', 'SSP126', 'SSP245').\n",
        "    ensemble (str): Ensemble member (e.g., 'r1i1p1f1').\n",
        "    climate_variable (str): Climate variable (e.g., 'pr' for precipitation).\n",
        "    start_year (int): Start year of the data range.\n",
        "    end_year (int): End year of the data range.\n",
        "    output_folder (str): Path to the output folder where files will be saved.\n",
        "\n",
        "    Usage:\n",
        "    cmip6_climate_data(\"ACCESS-CM2\", \"historical\", \"r1i1p1f1\", \"pr\", 1950, 1952, \"./output_folder\")\n",
        "    \"\"\"\n",
        "    # Ensure the output folder exists, if not, create it\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Construct the catalog URL\n",
        "    catalog_url = f\"https://ds.nccs.nasa.gov/thredds/catalog/AMES/NEX/GDDP-CMIP6/{model}/{timeframe}/{ensemble}/{climate_variable}/catalog.xml\"\n",
        "\n",
        "    # Retrieve the XML catalog\n",
        "    response = requests.get(catalog_url)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to retrieve the catalog. Status code: {response.status_code}\")\n",
        "        return\n",
        "\n",
        "    # Parse the XML\n",
        "    root = ET.fromstring(response.content)\n",
        "    ns = {'thredds': 'http://www.unidata.ucar.edu/namespaces/thredds/InvCatalog/v1.0'}\n",
        "\n",
        "    # Base URL for file downloads\n",
        "    base_url = \"https://ds.nccs.nasa.gov/thredds/fileServer/\"\n",
        "\n",
        "    # Extract file URLs and filter by year range\n",
        "    file_urls = []\n",
        "    for dataset in root.findall(\".//thredds:dataset\", ns):\n",
        "        url_path = dataset.attrib.get('urlPath')\n",
        "        if url_path:\n",
        "            year = int(url_path.split('_')[-1].split('.')[0])\n",
        "            if start_year <= year <= end_year:\n",
        "                file_urls.append(base_url + url_path)\n",
        "\n",
        "    # Download each file\n",
        "    for file_url in file_urls:\n",
        "        file_name = os.path.join(output_folder, file_url.split('/')[-1])\n",
        "        response = requests.get(file_url)\n",
        "        if response.status_code == 200:\n",
        "            with open(file_name, 'wb') as file:\n",
        "                file.write(response.content)\n",
        "            print(f\"Downloaded {file_name}\")\n",
        "        else:\n",
        "            print(f\"Failed to download {file_name}\")\n",
        "\n",
        "        # Optional: Throttle requests\n",
        "        # time.sleep(1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7zS4iFVrQy0d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}